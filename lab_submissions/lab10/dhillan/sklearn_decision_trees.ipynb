{
 "metadata": {
  "name": "",
  "signature": "sha256:c57617d33a393b4610707e435799557e50e437f5d3621b70cc3a1c3898201e83"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# do these first:\n",
      "# 1) brew install graphviz\n",
      "# 2) pip install pydot\n",
      "# 3) set directory to lesson 10\n",
      "import csv\n",
      "import numpy as np\n",
      "with open('./data/titanic.csv', 'r') as csvfile:\n",
      "    titanic_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Header contains feature names\n",
      "    row = titanic_reader.next()\n",
      "    feature_names = np.array(row)\n",
      "    \n",
      "    # Load dataset, and target classes\n",
      "    titanic_X, titanic_y = [], []\n",
      "    for row in titanic_reader:\n",
      "        if row[4] != '':\n",
      "            titanic_X.append(row)\n",
      "            titanic_y.append(row[0]) # The target value is \"survived\"\n",
      "    # Changing to arrays\n",
      "    titanic_X = np.array(titanic_X)\n",
      "    titanic_y = np.array(titanic_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Inspecting last row, header, features and target\n",
      "print feature_names\n",
      "print row\n",
      "\n",
      "print titanic_X[0]\n",
      "print titanic_y[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['survived' 'pclass' 'name' 'sex' 'age' 'sibsp' 'parch' 'ticket' 'fare'\n",
        " 'cabin' 'embarked']\n",
        "['0', '3', 'Dooley, Mr. Patrick', 'male', '32', '0', '0', '370376', '7.75', '', 'Q']\n",
        "['0' '3' 'Braund, Mr. Owen Harris' 'male' '22' '1' '0' 'A/5 21171' '7.25'\n",
        " '' 'S']\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We keep the class, age and sex variables\n",
      "titanic_X = titanic_X[:, [1, 4, 3, 8]]\n",
      "feature_names = feature_names[[1, 4, 3,8]]\n",
      "\n",
      "# We have missing values for age, so we're going to assign the mean value\n",
      "# ages = titanic_X[:, 1]\n",
      "\n",
      "# Is this reasonable?\n",
      "# mean_age = np.mean(titanic_X[ages != '', 1].astype(np.float))\n",
      "# titanic_X[titanic_X[:, 1] == '', 1] = mean_age\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Encode sex as a categorical variable \n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "# This will normalize our class variables by giving them easily interpreted labels\n",
      "enc = LabelEncoder()\n",
      "# Creating categorical classes for sex\n",
      "label_encoder = enc.fit(titanic_X[:, 2])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "\n",
      "# Creating numerical classes for sex\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
      "print \"Integer classes:\", integer_classes\n",
      "t = label_encoder.transform(titanic_X[:, 2])\n",
      "titanic_X[:, 2] = t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['female' 'male']\n",
        "Integer classes: [0 1]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inspect\n",
      "print feature_names\n",
      "print titanic_X[10], titanic_y[10]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['pclass' 'age' 'sex' 'fare']\n",
        "['1' '58' '0' '26.55'] 1\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we encode 'class', which has more than 2 possible values\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(titanic_X[:, 0])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_).reshape(3, 1)\n",
      "print \"Integer classes:\", integer_classes\n",
      "enc = OneHotEncoder()\n",
      "one_hot_encoder = enc.fit(integer_classes)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['1' '2' '3']\n",
        "Integer classes: [[0]\n",
        " [1]\n",
        " [2]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# First, convert classes to 0-(N-1) integers using label_encoder\n",
      "num_of_rows = titanic_X.shape[0]\n",
      "t = label_encoder.transform(titanic_X[:, 0]).reshape(num_of_rows, 1)\n",
      "# Second, create a sparse matrix with three columns, each one indicating if the instance belongs to the class\n",
      "new_features = one_hot_encoder.transform(t)\n",
      "# Add the new features to titanix_X\n",
      "titanic_X = np.concatenate([titanic_X, new_features.toarray()], axis = 1)\n",
      "#Delete converted column\n",
      "titanic_X = np.delete(titanic_X, [0], 1)\n",
      "# Update feature names\n",
      "feature_names = ['age', 'sex', 'fare', 'first_class', 'second_class', 'third_class']\n",
      "# Convert to numerical values\n",
      "titanic_X = titanic_X.astype(float)\n",
      "titanic_y = titanic_y.astype(float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inspect\n",
      "print feature_names\n",
      "print titanic_X[0], titanic_y[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['age', 'sex', 'fare', 'first_class', 'second_class', 'third_class']\n",
        "[ 22.     1.     7.25   0.     0.     1.  ] 0.0\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create training and test sets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.25, random_state=33)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "### DECISION TREES ###\n",
      "\n",
      "# Fit a decision tree with the data using entropy to measure information gain\n",
      "from sklearn import tree\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
      "clf = clf.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Show the built tree, using pydot\n",
      "import pydot,StringIO\n",
      "dot_data = StringIO.StringIO() \n",
      "\n",
      "tree.export_graphviz(clf, out_file=dot_data, feature_names=['age','sex','fare','1st_class','2nd_class','3rd_class']) \n",
      "\n",
      "dot_data.getvalue()\n",
      "\n",
      "pydot.graph_from_dot_data(dot_data.getvalue())\n",
      "\n",
      "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
      "graph.write_pdf('titanic.pdf')\n",
      "print '\\nimage created!'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "image created!\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Create function to measure model performance\n",
      "from sklearn import metrics\n",
      "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
      "    y_pred=clf.predict(X)   \n",
      "    if show_accuracy:\n",
      "        print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\"\n",
      "    if show_classification_report:\n",
      "        print \"Classification report\"\n",
      "        print metrics.classification_report(y,y_pred),\"\\n\"\n",
      "    if show_confusion_matrix:\n",
      "        print \"Confusion matrix\"\n",
      "        print metrics.confusion_matrix(y,y_pred),\"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Measure Accuracy, precision, recall, f1 in the training set\n",
      "# Precision = true positives/(true positives + false positives). The ability of the classifier to not label a negative sample as positive\n",
      "# Recall = true positives/(true positives + false negatives). The ability of the classifier to find all positive samples\n",
      "# f1  = 2 * (precision * recall) / (precision + recall)\n",
      "measure_performance(X_train,y_train,clf, show_classification_report=True, show_confusion_matrix=True)\n",
      "\n",
      "# Perform leave-one-out cross validation to better measure performance, reducing variance\n",
      "from sklearn.cross_validation import cross_val_score, LeaveOneOut\n",
      "from scipy.stats import sem\n",
      "\n",
      "# Inspect documentation for LeaveOneOut\n",
      "#help(LeaveOneOut)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:0.821 \n",
        "\n",
        "Classification report\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.82      0.89      0.86       322\n",
        "        1.0       0.81      0.71      0.76       213\n",
        "\n",
        "avg / total       0.82      0.82      0.82       535\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[287  35]\n",
        " [ 61 152]] \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loo_cv(X_train,y_train,clf):\n",
      "    # Perform Leave-One-Out cross validation\n",
      "    loo = LeaveOneOut(X_train[:].shape[0])\n",
      "    scores=np.zeros(X_train[:].shape[0])\n",
      "    for train_index,test_index in loo:\n",
      "        X_train_cv, X_test_cv= X_train[train_index], X_train[test_index]\n",
      "        y_train_cv, y_test_cv= y_train[train_index], y_train[test_index]\n",
      "        clf = clf.fit(X_train_cv,y_train_cv)\n",
      "        y_pred=clf.predict(X_test_cv)\n",
      "        scores[test_index]=metrics.accuracy_score(y_test_cv.astype(int), y_pred.astype(int))\n",
      "    print (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loo_cv(X_train, y_train,clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean score: 0.817 (+/-0.017)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try to improve performance using Random Forests\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(criterion = 'entropy', n_estimators=10,random_state=33)\n",
      "clf = clf.fit(X_train,y_train)\n",
      "loo_cv(X_train,y_train,clf)\n",
      "# measure_performance(X_test,y_test,clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean score: 0.787 (+/-0.018)\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Attempt 1\n",
      "clf_dt=tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
      "clf_dt.fit(X_train,y_train)\n",
      "measure_performance(X_test,y_test,clf_dt)\n",
      "loo_cv(X_train,y_train,clf_dt)\n",
      "# Inspect documentation for DecisionTreeClassifier\n",
      "#help(tree.DecisionTreeClassifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:0.782 \n",
        "\n",
        "Classification report\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.79      0.83      0.81       102\n",
        "        1.0       0.76      0.71      0.74        77\n",
        "\n",
        "avg / total       0.78      0.78      0.78       179\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[85 17]\n",
        " [22 55]] \n",
        "\n",
        "Mean score: 0.817 (+/-0.017)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attempt 2\n",
      "clf_dt=tree.DecisionTreeClassifier(criterion='gini', max_depth=3,min_samples_leaf=5)\n",
      "clf_dt.fit(X_train,y_train)\n",
      "measure_performance(X_test,y_test,clf_dt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:0.782 \n",
        "\n",
        "Classification report\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.79      0.83      0.81       102\n",
        "        1.0       0.76      0.71      0.74        77\n",
        "\n",
        "avg / total       0.78      0.78      0.78       179\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[85 17]\n",
        " [22 55]] \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### A New Measure: the ROC and Area Under a Curve (AUC)\n",
      "\n",
      "# One way we can score a binary classification is by plotting the reciever \n",
      "# operating characteristic and determining the value of the area under curve (AUC). \n",
      "# Like above, our goal is to see an AUC as close to 1 as possible.\n",
      "\n",
      "# Syntax for roc_curve is roc_curve(actual, prediction, [pos_label if it's not 1])\n",
      "predictions = [p[1] for p in clf_dt.predict_proba(X_train)]\n",
      "fpr_p, tpr_p, thresholds_p = metrics.roc_curve(y_train,predictions)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "fig = plt.figure()\n",
      "fig.set_figwidth(10)\n",
      "fig.suptitle('AUC for Decision Tree Classifier Predicting Titanic Survivors')\n",
      "\n",
      "ax1 = plt.subplot(1, 2, 1)\n",
      "ax1.set_xlabel('false positive rate')\n",
      "ax1.set_ylabel('true positive rate')\n",
      "ax1.plot(fpr_p, tpr_p)\n",
      "\n",
      "fpr, tpr, thresholds = metrics.roc_curve(y_train,clf_dt.predict(X_train))\n",
      "ax2 = plt.subplot(1, 2, 2)\n",
      "ax2.set_xlabel('false positive rate')\n",
      "ax2.set_ylabel('true positive rate')\n",
      "ax2.plot(fpr, tpr)\n",
      "plt.show()\n",
      "\n",
      "print \"False-positive rate:\", fpr\n",
      "print \"True-positive rate: \", tpr\n",
      "print \"Thresholds:         \", thresholds\n",
      "\n",
      "fig.show()\n",
      "\n",
      "metrics.roc_auc_score(y_train, predictions)\n",
      "metrics.roc_auc_score(y_train,clf_dt.predict(X_train))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "False-positive rate: [ 0.          0.10869565  1.        ]\n",
        "True-positive rate:  [ 0.          0.71361502  1.        ]\n",
        "Thresholds:          [ 2.  1.  0.]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "0.8024596856501327"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "# HOMEWORK\n",
      "# Change some of the assumptions we've made throughout the lab to see how that changes the accuracy; Imputation, tree depth, samples, etc.\n",
      "# Try to find the most accurate model you can; talk about what you did, address the bias-variance tradeoff.\n",
      "# How could your accuracy be improved? Think internally to our model building and externally as well.\n",
      "#\n",
      "# NOTES:\n",
      "# Accuracy measured with loo_cv -\n",
      "# Testing base case with sex, class, age and replacing missing age with mean - \n",
      "#\n",
      "# DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5) = 0.802 (+/-0.015)\n",
      "# - DecisionTreeClassifier(criterion='gini', max_depth=3,min_samples_leaf=5) = 0.798 (+/-0.016)\n",
      "# - DecisionTreeClassifier(criterion='entropy', max_depth=5,min_samples_leaf=5) = 0.796 (+/-0.016)\n",
      "# - DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=10) = 0.790 (+/-0.016)\n",
      "# - RandomForestClassifier(criterion='entropy', n_estimators=10,random_state=33) = 0.796 (+/-0.016)\n",
      "# - RandomForestClassifier(criterion='entropy', n_estimators=5,random_state=33) = 0.801 (+/-0.015)\n",
      "# - RandomForestClassifier(criterion='gini', n_estimators=10,random_state=33) = 0.798 (+/-0.016)\n",
      "#\n",
      "# Different parameters only change accuracy by about 1%. Random forest doesn't do any better than\n",
      "# decision tree.\n",
      "#\n",
      "# Adding 'fare' feature:\n",
      "# - DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5) = 0.805 (+/-0.015)\n",
      "#\n",
      "# Marginal classification improvement. Probably not worth including because of decreased bias?\n",
      "#\n",
      "# Tried removing data where there was no age. This led to an accuracy improvement\n",
      "# - DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5) = 0.817 (+/-0.017)\n",
      "# Imputation: I guess it's often better to delete 'bad' data rather than to make a bad assumption?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    }
   ],
   "metadata": {}
  }
 ]
}